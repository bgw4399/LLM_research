{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 불러오기\n",
    "from TIRscore import self_intersection_n, core_token_counter_n, compute_TRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰으로 찢기 위해 토크나이저를 불러옴. 어떤 것을 사용해도 상관없지만 BERT Tokenizer 사용. 다른거 사용해봐도 좋을듯\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로드. 블로그에서 추출한 말뭉치 데이터셋 사용해보았음.\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"blog_authorship_corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16, 34살의 trian 데이터를 가져와 text만 뽑는다 \n",
    "underage_data = dataset[\"train\"].filter(lambda x: x[\"age\"] == 16).select_columns([\"text\"])\n",
    "old_data = dataset[\"train\"].filter(lambda x: x[\"age\"] == 34).select_columns([\"text\"])\n",
    "# 16살 valid 데이터를 가져와 text만 뽑는다\n",
    "underage_val = dataset[\"validation\"].filter(lambda x: x[\"age\"] == 16).select_columns([\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 0~30 까지로 shuffle 하면서 평균 점수 구해본다. 2중 포문으로 n도 늘려본다\n",
    "for n in range(2, 100):\n",
    "    meanS = [0, 0]\n",
    "    for i in range(30):\n",
    "        score1, score2 = compute_TRS(old_data, underage_data, underage_val, n=n, seed=i)\n",
    "        meanS[0] += score1\n",
    "        meanS[1] += score2\n",
    "    print(meanS/30)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
